{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN for handwritten recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdVcYuH7uhiH/9+7aURlNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PadariyaDebo/Synthetic-Data-Genration-using-GAN/blob/main/WGAN_for_handwritten_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaachwlLnlIu",
        "outputId": "a596f71a-ae01-40e2-a98d-c6ebd188bd94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(6265, 28, 28, 1)\n",
            ">1, c1=-2.439, c2=-0.003 g=-0.078\n",
            ">2, c1=-6.659, c2=0.100 g=-1.624\n",
            ">3, c1=-9.355, c2=0.181 g=-2.738\n",
            ">4, c1=-11.740, c2=0.274 g=-3.764\n",
            ">5, c1=-13.932, c2=0.321 g=-4.634\n",
            ">6, c1=-15.294, c2=0.398 g=-5.497\n",
            ">7, c1=-16.685, c2=0.437 g=-6.464\n",
            ">8, c1=-18.365, c2=0.471 g=-7.228\n",
            ">9, c1=-19.468, c2=0.546 g=-8.456\n",
            ">10, c1=-20.995, c2=0.591 g=-9.567\n",
            ">11, c1=-21.334, c2=0.674 g=-10.585\n",
            ">12, c1=-22.408, c2=0.753 g=-11.879\n",
            ">13, c1=-23.150, c2=0.840 g=-12.688\n",
            ">14, c1=-24.555, c2=0.908 g=-13.262\n",
            ">15, c1=-24.467, c2=1.007 g=-14.444\n",
            ">16, c1=-25.364, c2=1.102 g=-14.866\n",
            ">17, c1=-26.416, c2=1.190 g=-15.840\n",
            ">18, c1=-27.029, c2=1.236 g=-16.090\n",
            ">19, c1=-28.093, c2=1.314 g=-16.988\n",
            ">20, c1=-28.139, c2=1.398 g=-16.810\n",
            ">21, c1=-28.623, c2=1.411 g=-17.746\n",
            ">22, c1=-29.197, c2=1.456 g=-18.577\n",
            ">23, c1=-30.273, c2=1.474 g=-18.363\n",
            ">24, c1=-30.762, c2=1.524 g=-18.991\n",
            ">25, c1=-31.472, c2=1.481 g=-19.903\n",
            ">26, c1=-32.189, c2=1.460 g=-20.253\n",
            ">27, c1=-32.382, c2=1.460 g=-20.652\n",
            ">28, c1=-33.281, c2=1.302 g=-20.798\n",
            ">29, c1=-33.582, c2=1.312 g=-20.651\n",
            ">30, c1=-34.330, c2=1.112 g=-21.512\n",
            ">31, c1=-34.440, c2=0.931 g=-22.508\n",
            ">32, c1=-34.746, c2=0.783 g=-23.284\n",
            ">33, c1=-35.132, c2=0.484 g=-23.444\n",
            ">34, c1=-36.016, c2=0.049 g=-24.244\n",
            ">35, c1=-36.767, c2=-0.232 g=-25.273\n",
            ">36, c1=-35.769, c2=-0.829 g=-26.301\n",
            ">37, c1=-37.175, c2=-1.470 g=-26.594\n",
            ">38, c1=-37.576, c2=-2.266 g=-26.823\n",
            ">39, c1=-38.185, c2=-3.285 g=-27.817\n",
            ">40, c1=-38.499, c2=-4.375 g=-28.167\n",
            ">41, c1=-38.411, c2=-5.302 g=-29.771\n",
            ">42, c1=-39.488, c2=-6.655 g=-29.441\n",
            ">43, c1=-40.112, c2=-7.964 g=-30.717\n",
            ">44, c1=-40.547, c2=-8.908 g=-30.872\n",
            ">45, c1=-39.751, c2=-10.656 g=-31.042\n",
            ">46, c1=-41.612, c2=-12.020 g=-31.703\n",
            ">47, c1=-42.039, c2=-13.129 g=-32.716\n",
            ">48, c1=-42.158, c2=-15.314 g=-33.696\n",
            ">49, c1=-42.974, c2=-16.267 g=-33.875\n",
            ">50, c1=-42.856, c2=-17.987 g=-34.817\n",
            ">51, c1=-44.527, c2=-19.321 g=-35.687\n",
            ">52, c1=-44.054, c2=-20.797 g=-35.845\n",
            ">53, c1=-44.842, c2=-22.147 g=-37.548\n",
            ">54, c1=-45.716, c2=-23.481 g=-38.229\n",
            ">55, c1=-45.917, c2=-24.862 g=-38.731\n",
            ">56, c1=-46.501, c2=-26.095 g=-40.198\n",
            ">57, c1=-47.449, c2=-27.282 g=-40.660\n",
            ">58, c1=-48.173, c2=-28.555 g=-41.508\n",
            ">59, c1=-48.993, c2=-29.841 g=-42.394\n",
            ">60, c1=-49.287, c2=-30.832 g=-43.424\n",
            ">61, c1=-49.722, c2=-31.808 g=-43.805\n",
            ">62, c1=-51.157, c2=-33.099 g=-45.265\n",
            ">63, c1=-51.168, c2=-34.011 g=-46.273\n",
            ">64, c1=-51.810, c2=-34.972 g=-46.496\n",
            ">65, c1=-52.243, c2=-36.099 g=-48.311\n",
            ">66, c1=-52.840, c2=-36.673 g=-48.088\n",
            ">67, c1=-54.336, c2=-37.907 g=-48.408\n",
            ">68, c1=-54.474, c2=-38.459 g=-49.420\n",
            ">69, c1=-55.614, c2=-39.837 g=-50.470\n",
            ">70, c1=-55.346, c2=-39.957 g=-51.130\n",
            ">71, c1=-56.591, c2=-41.533 g=-51.930\n",
            ">72, c1=-57.334, c2=-42.043 g=-53.223\n",
            ">73, c1=-57.505, c2=-43.068 g=-53.674\n",
            ">74, c1=-58.952, c2=-43.617 g=-53.930\n",
            ">75, c1=-59.385, c2=-44.872 g=-55.017\n",
            ">76, c1=-59.610, c2=-45.189 g=-56.111\n",
            ">77, c1=-60.415, c2=-46.345 g=-56.684\n",
            ">78, c1=-61.345, c2=-46.843 g=-57.571\n",
            ">79, c1=-61.633, c2=-48.046 g=-58.147\n",
            ">80, c1=-62.776, c2=-48.528 g=-58.972\n",
            ">81, c1=-63.476, c2=-49.609 g=-59.723\n",
            ">82, c1=-64.144, c2=-49.904 g=-60.324\n",
            ">83, c1=-64.635, c2=-51.309 g=-61.720\n",
            ">84, c1=-64.783, c2=-51.462 g=-62.140\n",
            ">85, c1=-66.368, c2=-52.741 g=-63.241\n",
            ">86, c1=-66.218, c2=-53.102 g=-64.065\n",
            ">87, c1=-67.104, c2=-54.200 g=-64.433\n",
            ">88, c1=-67.591, c2=-54.882 g=-66.038\n",
            ">89, c1=-68.808, c2=-55.619 g=-66.334\n",
            ">90, c1=-69.366, c2=-56.128 g=-66.866\n",
            ">91, c1=-70.682, c2=-57.259 g=-68.395\n",
            ">92, c1=-71.060, c2=-57.453 g=-68.442\n",
            ">93, c1=-71.384, c2=-58.881 g=-69.606\n",
            ">94, c1=-72.236, c2=-59.146 g=-69.967\n",
            ">95, c1=-72.313, c2=-60.056 g=-71.124\n",
            ">96, c1=-73.118, c2=-61.046 g=-72.167\n",
            ">97, c1=-74.480, c2=-61.188 g=-71.816\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0097.png and model_0097.h5\n",
            ">98, c1=-75.430, c2=-62.675 g=-73.650\n",
            ">99, c1=-74.866, c2=-62.812 g=-74.597\n",
            ">100, c1=-76.380, c2=-64.071 g=-75.145\n",
            ">101, c1=-77.028, c2=-64.620 g=-76.384\n",
            ">102, c1=-78.328, c2=-65.660 g=-76.564\n",
            ">103, c1=-78.550, c2=-66.148 g=-77.634\n",
            ">104, c1=-79.300, c2=-67.026 g=-78.765\n",
            ">105, c1=-79.760, c2=-67.938 g=-79.629\n",
            ">106, c1=-80.472, c2=-68.420 g=-79.674\n",
            ">107, c1=-80.824, c2=-69.561 g=-80.707\n",
            ">108, c1=-81.943, c2=-69.812 g=-82.504\n",
            ">109, c1=-82.352, c2=-70.757 g=-82.548\n",
            ">110, c1=-83.156, c2=-71.641 g=-84.191\n",
            ">111, c1=-83.607, c2=-71.874 g=-84.144\n",
            ">112, c1=-85.390, c2=-73.250 g=-85.180\n",
            ">113, c1=-85.920, c2=-73.737 g=-86.608\n",
            ">114, c1=-86.821, c2=-74.663 g=-87.388\n",
            ">115, c1=-87.012, c2=-75.130 g=-87.464\n",
            ">116, c1=-87.909, c2=-76.260 g=-88.974\n",
            ">117, c1=-89.193, c2=-76.855 g=-90.088\n",
            ">118, c1=-88.677, c2=-77.804 g=-90.879\n",
            ">119, c1=-90.404, c2=-78.001 g=-92.092\n",
            ">120, c1=-90.970, c2=-79.167 g=-92.802\n",
            ">121, c1=-91.061, c2=-79.893 g=-93.913\n",
            ">122, c1=-91.995, c2=-80.626 g=-94.377\n",
            ">123, c1=-92.573, c2=-81.534 g=-95.398\n",
            ">124, c1=-93.425, c2=-82.018 g=-95.678\n",
            ">125, c1=-94.015, c2=-83.308 g=-97.015\n",
            ">126, c1=-95.567, c2=-83.909 g=-98.096\n",
            ">127, c1=-95.109, c2=-84.282 g=-97.977\n",
            ">128, c1=-96.388, c2=-85.793 g=-99.090\n",
            ">129, c1=-97.864, c2=-85.809 g=-100.300\n",
            ">130, c1=-98.481, c2=-87.012 g=-101.615\n",
            ">131, c1=-99.076, c2=-87.395 g=-102.422\n",
            ">132, c1=-99.368, c2=-88.313 g=-103.643\n",
            ">133, c1=-100.337, c2=-89.242 g=-103.421\n",
            ">134, c1=-101.136, c2=-90.086 g=-105.170\n",
            ">135, c1=-101.847, c2=-90.553 g=-105.285\n",
            ">136, c1=-102.355, c2=-91.862 g=-106.538\n",
            ">137, c1=-103.644, c2=-92.206 g=-107.966\n",
            ">138, c1=-103.967, c2=-93.056 g=-108.660\n",
            ">139, c1=-105.311, c2=-93.884 g=-109.677\n",
            ">140, c1=-105.784, c2=-94.527 g=-108.377\n",
            ">141, c1=-106.342, c2=-96.118 g=-110.321\n",
            ">142, c1=-107.650, c2=-96.127 g=-111.964\n",
            ">143, c1=-108.096, c2=-97.124 g=-112.965\n",
            ">144, c1=-109.066, c2=-97.620 g=-113.026\n",
            ">145, c1=-108.906, c2=-99.070 g=-114.244\n",
            ">146, c1=-110.772, c2=-99.279 g=-114.951\n",
            ">147, c1=-110.811, c2=-100.526 g=-116.343\n",
            ">148, c1=-110.896, c2=-101.005 g=-116.950\n",
            ">149, c1=-112.449, c2=-101.638 g=-117.489\n",
            ">150, c1=-113.343, c2=-102.763 g=-118.863\n",
            ">151, c1=-114.698, c2=-102.988 g=-119.396\n",
            ">152, c1=-115.101, c2=-104.364 g=-120.427\n",
            ">153, c1=-115.477, c2=-104.813 g=-120.852\n",
            ">154, c1=-116.251, c2=-106.187 g=-122.079\n",
            ">155, c1=-117.142, c2=-106.422 g=-122.925\n",
            ">156, c1=-118.038, c2=-107.284 g=-123.773\n",
            ">157, c1=-119.248, c2=-108.379 g=-124.729\n",
            ">158, c1=-118.713, c2=-108.475 g=-125.149\n",
            ">159, c1=-120.274, c2=-109.949 g=-126.486\n",
            ">160, c1=-120.391, c2=-109.996 g=-127.444\n",
            ">161, c1=-120.350, c2=-111.087 g=-127.128\n",
            ">162, c1=-122.152, c2=-112.488 g=-128.074\n",
            ">163, c1=-123.400, c2=-112.959 g=-128.837\n",
            ">164, c1=-124.001, c2=-114.077 g=-130.455\n",
            ">165, c1=-125.407, c2=-114.815 g=-131.556\n",
            ">166, c1=-125.513, c2=-114.804 g=-132.211\n",
            ">167, c1=-126.860, c2=-116.252 g=-133.461\n",
            ">168, c1=-127.331, c2=-116.422 g=-134.383\n",
            ">169, c1=-128.861, c2=-117.328 g=-134.224\n",
            ">170, c1=-129.012, c2=-118.937 g=-135.520\n",
            ">171, c1=-129.963, c2=-118.991 g=-136.829\n",
            ">172, c1=-131.344, c2=-119.932 g=-137.303\n",
            ">173, c1=-131.639, c2=-121.051 g=-138.324\n",
            ">174, c1=-132.149, c2=-121.083 g=-139.222\n",
            ">175, c1=-132.836, c2=-122.410 g=-139.879\n",
            ">176, c1=-132.785, c2=-123.460 g=-140.825\n",
            ">177, c1=-135.413, c2=-124.099 g=-141.605\n",
            ">178, c1=-135.369, c2=-125.023 g=-142.482\n",
            ">179, c1=-135.705, c2=-125.937 g=-143.064\n",
            ">180, c1=-137.464, c2=-127.020 g=-144.177\n",
            ">181, c1=-139.106, c2=-127.019 g=-145.367\n",
            ">182, c1=-138.161, c2=-127.027 g=-146.000\n",
            ">183, c1=-139.864, c2=-128.537 g=-146.520\n",
            ">184, c1=-140.043, c2=-130.223 g=-147.473\n",
            ">185, c1=-141.206, c2=-130.911 g=-148.664\n",
            ">186, c1=-141.522, c2=-131.258 g=-149.099\n",
            ">187, c1=-143.042, c2=-132.673 g=-150.352\n",
            ">188, c1=-143.506, c2=-133.144 g=-151.264\n",
            ">189, c1=-144.128, c2=-133.768 g=-151.853\n",
            ">190, c1=-145.373, c2=-135.026 g=-152.449\n",
            ">191, c1=-144.923, c2=-134.099 g=-152.762\n",
            ">192, c1=-147.453, c2=-136.794 g=-154.045\n",
            ">193, c1=-147.891, c2=-137.789 g=-155.280\n",
            ">194, c1=-148.238, c2=-137.636 g=-154.133\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0194.png and model_0194.h5\n",
            ">195, c1=-149.905, c2=-139.652 g=-155.964\n",
            ">196, c1=-149.750, c2=-138.813 g=-157.487\n",
            ">197, c1=-151.426, c2=-140.651 g=-158.670\n",
            ">198, c1=-152.157, c2=-141.318 g=-159.757\n",
            ">199, c1=-152.467, c2=-141.619 g=-160.660\n",
            ">200, c1=-152.197, c2=-142.542 g=-159.756\n",
            ">201, c1=-153.875, c2=-144.392 g=-161.906\n",
            ">202, c1=-156.038, c2=-145.140 g=-163.207\n",
            ">203, c1=-156.731, c2=-145.574 g=-164.135\n",
            ">204, c1=-155.780, c2=-145.518 g=-164.107\n",
            ">205, c1=-157.462, c2=-147.335 g=-165.503\n",
            ">206, c1=-158.677, c2=-148.152 g=-166.423\n",
            ">207, c1=-159.499, c2=-149.038 g=-167.442\n",
            ">208, c1=-160.124, c2=-149.232 g=-167.324\n",
            ">209, c1=-160.894, c2=-151.210 g=-168.688\n",
            ">210, c1=-162.442, c2=-151.724 g=-169.503\n",
            ">211, c1=-162.658, c2=-150.978 g=-171.056\n",
            ">212, c1=-163.094, c2=-151.998 g=-169.823\n",
            ">213, c1=-165.412, c2=-154.547 g=-172.554\n",
            ">214, c1=-165.703, c2=-154.329 g=-172.761\n",
            ">215, c1=-166.100, c2=-156.145 g=-174.314\n",
            ">216, c1=-166.687, c2=-155.981 g=-173.797\n",
            ">217, c1=-167.411, c2=-158.230 g=-175.714\n",
            ">218, c1=-168.406, c2=-158.000 g=-177.011\n",
            ">219, c1=-169.814, c2=-158.131 g=-177.731\n",
            ">220, c1=-169.730, c2=-159.289 g=-178.434\n",
            ">221, c1=-171.448, c2=-160.135 g=-179.577\n",
            ">222, c1=-172.157, c2=-160.793 g=-179.642\n",
            ">223, c1=-173.203, c2=-162.830 g=-181.278\n",
            ">224, c1=-173.272, c2=-162.773 g=-179.219\n",
            ">225, c1=-174.857, c2=-165.509 g=-181.632\n",
            ">226, c1=-174.753, c2=-164.410 g=-181.719\n",
            ">227, c1=-176.841, c2=-166.580 g=-184.349\n",
            ">228, c1=-178.296, c2=-167.017 g=-185.589\n",
            ">229, c1=-178.840, c2=-167.627 g=-186.487\n",
            ">230, c1=-178.463, c2=-167.993 g=-187.112\n",
            ">231, c1=-179.520, c2=-169.190 g=-188.308\n",
            ">232, c1=-180.808, c2=-169.363 g=-188.818\n",
            ">233, c1=-181.226, c2=-171.216 g=-189.215\n",
            ">234, c1=-182.318, c2=-172.449 g=-190.530\n",
            ">235, c1=-183.371, c2=-172.503 g=-191.570\n",
            ">236, c1=-184.900, c2=-171.990 g=-191.526\n",
            ">237, c1=-185.237, c2=-174.652 g=-193.204\n",
            ">238, c1=-186.496, c2=-175.301 g=-194.144\n",
            ">239, c1=-185.760, c2=-176.563 g=-195.271\n",
            ">240, c1=-187.741, c2=-176.922 g=-195.920\n",
            ">241, c1=-189.143, c2=-178.333 g=-197.181\n",
            ">242, c1=-188.411, c2=-177.547 g=-196.466\n",
            ">243, c1=-189.822, c2=-180.889 g=-198.196\n",
            ">244, c1=-191.354, c2=-179.250 g=-199.522\n",
            ">245, c1=-191.806, c2=-181.125 g=-200.547\n",
            ">246, c1=-192.803, c2=-181.228 g=-201.151\n",
            ">247, c1=-194.641, c2=-182.686 g=-201.947\n",
            ">248, c1=-194.848, c2=-184.382 g=-202.740\n",
            ">249, c1=-196.248, c2=-185.637 g=-203.490\n",
            ">250, c1=-196.552, c2=-182.946 g=-202.924\n",
            ">251, c1=-197.254, c2=-187.176 g=-205.802\n",
            ">252, c1=-197.149, c2=-186.145 g=-204.036\n",
            ">253, c1=-199.430, c2=-189.877 g=-207.450\n",
            ">254, c1=-201.008, c2=-189.600 g=-208.981\n",
            ">255, c1=-200.780, c2=-189.428 g=-209.577\n",
            ">256, c1=-201.699, c2=-188.091 g=-208.160\n",
            ">257, c1=-202.219, c2=-192.236 g=-210.738\n",
            ">258, c1=-203.097, c2=-190.711 g=-211.453\n",
            ">259, c1=-201.327, c2=-192.532 g=-212.359\n",
            ">260, c1=-204.571, c2=-194.628 g=-212.185\n",
            ">261, c1=-205.710, c2=-196.532 g=-214.838\n",
            ">262, c1=-206.360, c2=-196.255 g=-215.877\n",
            ">263, c1=-207.939, c2=-194.719 g=-216.324\n",
            ">264, c1=-209.351, c2=-197.030 g=-215.586\n",
            ">265, c1=-210.783, c2=-200.429 g=-218.164\n",
            ">266, c1=-210.455, c2=-200.230 g=-219.449\n",
            ">267, c1=-211.457, c2=-199.756 g=-220.417\n",
            ">268, c1=-212.789, c2=-198.764 g=-219.474\n",
            ">269, c1=-212.903, c2=-202.338 g=-221.915\n",
            ">270, c1=-212.861, c2=-200.329 g=-222.614\n",
            ">271, c1=-215.904, c2=-199.870 g=-221.254\n",
            ">272, c1=-215.401, c2=-205.166 g=-224.623\n",
            ">273, c1=-216.189, c2=-205.452 g=-225.658\n",
            ">274, c1=-217.256, c2=-205.140 g=-225.668\n",
            ">275, c1=-217.961, c2=-207.172 g=-227.246\n",
            ">276, c1=-218.937, c2=-208.078 g=-228.256\n",
            ">277, c1=-221.034, c2=-208.149 g=-229.223\n",
            ">278, c1=-220.667, c2=-206.700 g=-229.610\n",
            ">279, c1=-218.672, c2=-208.397 g=-230.167\n",
            ">280, c1=-223.277, c2=-211.685 g=-231.546\n",
            ">281, c1=-223.756, c2=-211.546 g=-231.748\n",
            ">282, c1=-226.096, c2=-215.096 g=-233.192\n",
            ">283, c1=-223.275, c2=-208.774 g=-231.195\n",
            ">284, c1=-227.081, c2=-216.066 g=-234.553\n",
            ">285, c1=-228.202, c2=-216.953 g=-236.652\n",
            ">286, c1=-227.567, c2=-215.513 g=-237.395\n",
            ">287, c1=-227.749, c2=-214.225 g=-236.752\n",
            ">288, c1=-228.097, c2=-219.303 g=-237.045\n",
            ">289, c1=-230.148, c2=-222.405 g=-240.084\n",
            ">290, c1=-232.664, c2=-220.900 g=-241.151\n",
            ">291, c1=-231.750, c2=-219.782 g=-240.533\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0291.png and model_0291.h5\n",
            ">292, c1=-234.406, c2=-223.020 g=-242.557\n",
            ">293, c1=-234.687, c2=-218.462 g=-241.789\n",
            ">294, c1=-234.860, c2=-224.444 g=-244.148\n",
            ">295, c1=-234.406, c2=-224.369 g=-244.515\n",
            ">296, c1=-237.927, c2=-227.708 g=-246.411\n",
            ">297, c1=-239.353, c2=-226.626 g=-247.467\n",
            ">298, c1=-238.560, c2=-221.025 g=-246.595\n",
            ">299, c1=-239.302, c2=-228.123 g=-248.350\n",
            ">300, c1=-241.015, c2=-228.253 g=-249.607\n",
            ">301, c1=-241.475, c2=-228.222 g=-249.693\n",
            ">302, c1=-241.885, c2=-231.360 g=-251.219\n",
            ">303, c1=-243.049, c2=-230.738 g=-252.259\n",
            ">304, c1=-243.516, c2=-231.529 g=-252.690\n",
            ">305, c1=-244.495, c2=-234.414 g=-254.200\n",
            ">306, c1=-244.017, c2=-223.549 g=-251.793\n",
            ">307, c1=-244.949, c2=-235.285 g=-255.473\n",
            ">308, c1=-245.795, c2=-231.125 g=-252.187\n",
            ">309, c1=-246.948, c2=-239.190 g=-256.346\n",
            ">310, c1=-248.064, c2=-239.852 g=-257.840\n",
            ">311, c1=-249.193, c2=-239.828 g=-259.586\n",
            ">312, c1=-252.197, c2=-239.653 g=-260.846\n",
            ">313, c1=-252.214, c2=-234.149 g=-260.793\n",
            ">314, c1=-250.810, c2=-234.171 g=-259.625\n",
            ">315, c1=-249.880, c2=-240.509 g=-262.386\n",
            ">316, c1=-253.855, c2=-239.564 g=-262.242\n",
            ">317, c1=-255.118, c2=-241.853 g=-264.601\n",
            ">318, c1=-254.428, c2=-238.945 g=-263.227\n",
            ">319, c1=-254.900, c2=-243.513 g=-265.514\n",
            ">320, c1=-256.665, c2=-242.448 g=-266.127\n",
            ">321, c1=-256.769, c2=-240.377 g=-265.205\n",
            ">322, c1=-255.636, c2=-247.234 g=-268.038\n",
            ">323, c1=-256.061, c2=-243.114 g=-265.815\n",
            ">324, c1=-258.785, c2=-252.883 g=-270.614\n",
            ">325, c1=-260.575, c2=-244.656 g=-271.276\n",
            ">326, c1=-257.565, c2=-234.253 g=-266.750\n",
            ">327, c1=-259.617, c2=-250.985 g=-270.187\n",
            ">328, c1=-260.290, c2=-251.279 g=-272.437\n",
            ">329, c1=-262.090, c2=-245.680 g=-272.149\n",
            ">330, c1=-262.353, c2=-249.880 g=-274.930\n",
            ">331, c1=-261.167, c2=-238.490 g=-271.912\n",
            ">332, c1=-263.353, c2=-250.075 g=-274.424\n",
            ">333, c1=-263.349, c2=-254.624 g=-277.381\n",
            ">334, c1=-258.505, c2=-225.486 g=-271.413\n",
            ">335, c1=-261.748, c2=-252.641 g=-277.007\n",
            ">336, c1=-265.880, c2=-248.008 g=-276.705\n",
            ">337, c1=-261.724, c2=-252.327 g=-278.647\n",
            ">338, c1=-263.257, c2=-253.942 g=-277.542\n",
            ">339, c1=-266.543, c2=-261.334 g=-281.070\n",
            ">340, c1=-271.865, c2=-260.454 g=-282.915\n",
            ">341, c1=-268.167, c2=-253.950 g=-283.162\n",
            ">342, c1=-270.913, c2=-257.528 g=-285.223\n",
            ">343, c1=-268.972, c2=-240.324 g=-282.044\n",
            ">344, c1=-262.995, c2=-244.091 g=-279.527\n",
            ">345, c1=-266.335, c2=-257.881 g=-283.912\n",
            ">346, c1=-267.294, c2=-255.814 g=-283.080\n",
            ">347, c1=-270.672, c2=-254.539 g=-284.987\n",
            ">348, c1=-265.994, c2=-257.515 g=-286.791\n",
            ">349, c1=-270.079, c2=-253.564 g=-285.467\n",
            ">350, c1=-272.147, c2=-261.631 g=-289.154\n",
            ">351, c1=-264.347, c2=-246.047 g=-288.926\n",
            ">352, c1=-270.152, c2=-250.292 g=-287.268\n",
            ">353, c1=-267.703, c2=-245.638 g=-286.815\n",
            ">354, c1=-266.743, c2=-253.964 g=-287.452\n",
            ">355, c1=-269.294, c2=-255.944 g=-288.572\n",
            ">356, c1=-266.815, c2=-251.013 g=-292.034\n",
            ">357, c1=-256.402, c2=-217.764 g=-283.255\n",
            ">358, c1=-254.777, c2=-244.126 g=-286.405\n",
            ">359, c1=-253.742, c2=-249.158 g=-287.565\n",
            ">360, c1=-264.349, c2=-257.041 g=-290.965\n",
            ">361, c1=-266.341, c2=-254.750 g=-292.944\n",
            ">362, c1=-259.976, c2=-241.389 g=-291.095\n",
            ">363, c1=-266.611, c2=-252.615 g=-291.721\n",
            ">364, c1=-259.293, c2=-245.052 g=-292.061\n",
            ">365, c1=-266.499, c2=-239.221 g=-289.976\n",
            ">366, c1=-244.737, c2=-222.539 g=-286.557\n",
            ">367, c1=-244.385, c2=-221.867 g=-289.270\n",
            ">368, c1=-226.667, c2=-178.130 g=-283.726\n",
            ">369, c1=-195.843, c2=-177.738 g=-281.099\n",
            ">370, c1=-193.557, c2=-185.150 g=-280.553\n",
            ">371, c1=-173.818, c2=-176.583 g=-282.265\n",
            ">372, c1=-195.839, c2=-200.778 g=-281.267\n",
            ">373, c1=-195.620, c2=-179.940 g=-278.970\n",
            ">374, c1=-159.161, c2=-192.007 g=-281.820\n",
            ">375, c1=-215.395, c2=-197.524 g=-280.241\n",
            ">376, c1=-197.537, c2=-165.836 g=-277.341\n",
            ">377, c1=-169.468, c2=-99.004 g=-268.129\n",
            ">378, c1=-133.812, c2=-65.218 g=-255.388\n",
            ">379, c1=-56.482, c2=-29.119 g=-234.754\n",
            ">380, c1=-63.554, c2=-22.693 g=-226.888\n",
            ">381, c1=-60.163, c2=20.969 g=-215.236\n",
            ">382, c1=-46.440, c2=42.394 g=-198.552\n",
            ">383, c1=-52.957, c2=37.362 g=-191.594\n",
            ">384, c1=-27.194, c2=44.501 g=-178.929\n",
            ">385, c1=-18.644, c2=32.488 g=-169.029\n",
            ">386, c1=-42.585, c2=23.112 g=-173.830\n",
            ">387, c1=-29.135, c2=9.761 g=-175.250\n",
            ">388, c1=-50.550, c2=0.375 g=-188.330\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0388.png and model_0388.h5\n",
            ">389, c1=-52.507, c2=-6.123 g=-196.859\n",
            ">390, c1=-53.946, c2=-4.231 g=-203.022\n",
            ">391, c1=-54.610, c2=-7.383 g=-206.040\n",
            ">392, c1=-58.181, c2=-5.573 g=-206.939\n",
            ">393, c1=-39.245, c2=0.319 g=-204.394\n",
            ">394, c1=-58.351, c2=1.892 g=-202.154\n",
            ">395, c1=-67.097, c2=8.097 g=-200.560\n",
            ">396, c1=-49.596, c2=13.758 g=-193.407\n",
            ">397, c1=-50.370, c2=15.348 g=-188.074\n",
            ">398, c1=-67.191, c2=22.864 g=-185.109\n",
            ">399, c1=-71.323, c2=30.342 g=-181.543\n",
            ">400, c1=-69.019, c2=34.535 g=-178.134\n",
            ">401, c1=-76.777, c2=37.238 g=-176.564\n",
            ">402, c1=-66.936, c2=40.393 g=-171.158\n",
            ">403, c1=-76.557, c2=45.744 g=-167.861\n",
            ">404, c1=-72.579, c2=49.951 g=-163.648\n",
            ">405, c1=-82.124, c2=52.179 g=-160.910\n",
            ">406, c1=-87.453, c2=52.205 g=-158.272\n",
            ">407, c1=-95.610, c2=50.174 g=-158.814\n",
            ">408, c1=-98.044, c2=47.963 g=-155.179\n",
            ">409, c1=-104.330, c2=44.812 g=-152.473\n",
            ">410, c1=-102.806, c2=38.721 g=-149.565\n",
            ">411, c1=-114.508, c2=33.213 g=-149.174\n",
            ">412, c1=-125.245, c2=23.400 g=-145.471\n",
            ">413, c1=-126.141, c2=15.791 g=-144.521\n",
            ">414, c1=-128.987, c2=10.152 g=-140.859\n",
            ">415, c1=-136.093, c2=4.152 g=-138.991\n",
            ">416, c1=-144.157, c2=-3.492 g=-136.305\n",
            ">417, c1=-152.281, c2=-8.638 g=-134.660\n",
            ">418, c1=-153.818, c2=-12.047 g=-129.765\n",
            ">419, c1=-164.454, c2=-17.781 g=-128.371\n",
            ">420, c1=-175.697, c2=-23.532 g=-126.750\n",
            ">421, c1=-183.222, c2=-30.574 g=-126.527\n",
            ">422, c1=-188.011, c2=-37.491 g=-126.733\n",
            ">423, c1=-196.961, c2=-46.480 g=-126.831\n",
            ">424, c1=-196.065, c2=-51.834 g=-125.679\n",
            ">425, c1=-202.870, c2=-57.168 g=-122.238\n",
            ">426, c1=-211.776, c2=-61.180 g=-127.092\n",
            ">427, c1=-214.771, c2=-69.559 g=-126.634\n",
            ">428, c1=-223.924, c2=-73.616 g=-127.156\n",
            ">429, c1=-226.517, c2=-78.977 g=-125.435\n",
            ">430, c1=-233.956, c2=-85.982 g=-121.030\n",
            ">431, c1=-232.829, c2=-90.818 g=-109.859\n",
            ">432, c1=-241.292, c2=-102.296 g=-89.644\n",
            ">433, c1=-242.099, c2=-111.223 g=-64.648\n",
            ">434, c1=-248.584, c2=-126.511 g=-38.675\n",
            ">435, c1=-251.584, c2=-139.316 g=-4.306\n",
            ">436, c1=-257.637, c2=-145.666 g=32.084\n",
            ">437, c1=-261.093, c2=-153.185 g=61.243\n",
            ">438, c1=-263.285, c2=-161.624 g=83.374\n",
            ">439, c1=-266.425, c2=-163.926 g=100.966\n",
            ">440, c1=-269.109, c2=-167.738 g=109.617\n",
            ">441, c1=-270.917, c2=-172.124 g=116.411\n",
            ">442, c1=-269.292, c2=-171.850 g=123.867\n",
            ">443, c1=-274.361, c2=-174.984 g=127.942\n",
            ">444, c1=-276.457, c2=-177.628 g=135.098\n",
            ">445, c1=-279.152, c2=-181.967 g=141.326\n",
            ">446, c1=-282.803, c2=-184.279 g=147.547\n",
            ">447, c1=-282.791, c2=-190.107 g=156.248\n",
            ">448, c1=-288.658, c2=-200.425 g=164.483\n",
            ">449, c1=-291.920, c2=-213.140 g=177.181\n",
            ">450, c1=-295.470, c2=-226.156 g=188.345\n",
            ">451, c1=-300.522, c2=-238.904 g=204.031\n",
            ">452, c1=-304.165, c2=-248.323 g=215.516\n",
            ">453, c1=-307.483, c2=-257.375 g=225.868\n",
            ">454, c1=-311.711, c2=-268.157 g=233.195\n",
            ">455, c1=-315.398, c2=-273.436 g=238.184\n",
            ">456, c1=-321.179, c2=-280.756 g=245.412\n",
            ">457, c1=-324.170, c2=-284.820 g=252.249\n",
            ">458, c1=-326.727, c2=-289.321 g=255.294\n",
            ">459, c1=-330.081, c2=-293.709 g=258.974\n",
            ">460, c1=-334.048, c2=-297.237 g=263.988\n",
            ">461, c1=-336.124, c2=-300.935 g=269.465\n",
            ">462, c1=-340.197, c2=-303.818 g=274.022\n",
            ">463, c1=-342.787, c2=-307.769 g=277.195\n",
            ">464, c1=-346.628, c2=-310.785 g=283.020\n",
            ">465, c1=-349.232, c2=-315.123 g=285.654\n",
            ">466, c1=-351.527, c2=-317.491 g=289.986\n",
            ">467, c1=-354.101, c2=-321.940 g=296.454\n",
            ">468, c1=-357.572, c2=-325.186 g=302.896\n",
            ">469, c1=-359.168, c2=-327.945 g=305.916\n",
            ">470, c1=-362.204, c2=-329.974 g=310.976\n",
            ">471, c1=-364.374, c2=-332.636 g=314.990\n",
            ">472, c1=-366.384, c2=-336.433 g=319.507\n",
            ">473, c1=-369.139, c2=-337.981 g=323.381\n",
            ">474, c1=-371.603, c2=-341.432 g=328.407\n",
            ">475, c1=-372.885, c2=-343.491 g=332.651\n",
            ">476, c1=-375.690, c2=-345.785 g=335.995\n",
            ">477, c1=-377.540, c2=-347.651 g=339.885\n",
            ">478, c1=-379.664, c2=-350.576 g=343.104\n",
            ">479, c1=-381.510, c2=-352.055 g=345.984\n",
            ">480, c1=-382.795, c2=-354.633 g=349.411\n",
            ">481, c1=-385.434, c2=-356.130 g=352.731\n",
            ">482, c1=-387.524, c2=-358.643 g=354.432\n",
            ">483, c1=-389.019, c2=-360.283 g=357.429\n",
            ">484, c1=-390.101, c2=-362.044 g=359.507\n",
            ">485, c1=-392.307, c2=-364.122 g=361.629\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0485.png and model_0485.h5\n",
            ">486, c1=-393.913, c2=-366.050 g=363.842\n",
            ">487, c1=-394.954, c2=-367.560 g=365.990\n",
            ">488, c1=-397.092, c2=-369.020 g=367.940\n",
            ">489, c1=-398.916, c2=-370.751 g=369.882\n",
            ">490, c1=-400.574, c2=-371.849 g=371.113\n",
            ">491, c1=-402.385, c2=-373.317 g=372.779\n",
            ">492, c1=-403.589, c2=-374.712 g=373.921\n",
            ">493, c1=-404.434, c2=-376.320 g=375.516\n",
            ">494, c1=-405.927, c2=-377.687 g=376.943\n",
            ">495, c1=-408.422, c2=-379.087 g=378.463\n",
            ">496, c1=-410.217, c2=-380.153 g=379.895\n",
            ">497, c1=-411.597, c2=-381.762 g=381.053\n",
            ">498, c1=-413.610, c2=-382.904 g=382.600\n",
            ">499, c1=-414.177, c2=-384.089 g=384.245\n",
            ">500, c1=-416.442, c2=-385.646 g=385.198\n",
            ">501, c1=-418.035, c2=-387.167 g=386.735\n",
            ">502, c1=-418.498, c2=-388.302 g=388.206\n",
            ">503, c1=-420.131, c2=-389.489 g=389.550\n",
            ">504, c1=-421.782, c2=-390.466 g=390.939\n",
            ">505, c1=-423.187, c2=-392.110 g=392.061\n",
            ">506, c1=-424.609, c2=-392.876 g=393.111\n",
            ">507, c1=-425.019, c2=-394.145 g=394.482\n",
            ">508, c1=-427.555, c2=-395.204 g=395.733\n",
            ">509, c1=-428.510, c2=-396.396 g=397.024\n",
            ">510, c1=-429.784, c2=-397.416 g=398.206\n",
            ">511, c1=-431.143, c2=-398.164 g=399.350\n",
            ">512, c1=-432.128, c2=-399.051 g=400.367\n",
            ">513, c1=-433.717, c2=-399.416 g=401.434\n",
            ">514, c1=-434.390, c2=-400.672 g=402.254\n",
            ">515, c1=-436.345, c2=-402.131 g=403.589\n",
            ">516, c1=-438.579, c2=-403.071 g=404.720\n",
            ">517, c1=-438.694, c2=-404.494 g=405.899\n",
            ">518, c1=-439.917, c2=-405.920 g=407.221\n",
            ">519, c1=-441.326, c2=-406.623 g=408.396\n",
            ">520, c1=-442.841, c2=-407.779 g=409.163\n",
            ">521, c1=-444.206, c2=-409.219 g=410.445\n",
            ">522, c1=-445.271, c2=-409.822 g=411.426\n",
            ">523, c1=-447.009, c2=-410.762 g=412.407\n",
            ">524, c1=-447.500, c2=-410.747 g=413.543\n",
            ">525, c1=-449.224, c2=-411.686 g=414.241\n",
            ">526, c1=-450.584, c2=-411.893 g=415.359\n",
            ">527, c1=-452.045, c2=-411.500 g=416.358\n",
            ">528, c1=-452.889, c2=-411.949 g=416.744\n",
            ">529, c1=-453.346, c2=-410.549 g=417.368\n",
            ">530, c1=-453.417, c2=-408.476 g=418.163\n",
            ">531, c1=-454.307, c2=-408.595 g=418.332\n",
            ">532, c1=-456.086, c2=-403.621 g=418.420\n",
            ">533, c1=-455.676, c2=-404.843 g=418.462\n",
            ">534, c1=-456.086, c2=-398.647 g=417.258\n",
            ">535, c1=-456.144, c2=-394.226 g=416.335\n",
            ">536, c1=-456.074, c2=-388.496 g=414.173\n",
            ">537, c1=-455.859, c2=-384.897 g=412.882\n",
            ">538, c1=-454.625, c2=-371.719 g=409.937\n",
            ">539, c1=-452.903, c2=-368.986 g=405.197\n",
            ">540, c1=-451.616, c2=-362.393 g=403.701\n",
            ">541, c1=-451.129, c2=-365.812 g=402.047\n",
            ">542, c1=-451.294, c2=-367.433 g=401.581\n",
            ">543, c1=-451.490, c2=-374.551 g=402.851\n",
            ">544, c1=-455.074, c2=-374.299 g=404.751\n",
            ">545, c1=-453.636, c2=-377.232 g=404.151\n",
            ">546, c1=-454.661, c2=-384.752 g=408.837\n",
            ">547, c1=-454.853, c2=-384.839 g=409.060\n",
            ">548, c1=-457.107, c2=-389.796 g=412.597\n",
            ">549, c1=-458.264, c2=-388.976 g=414.574\n",
            ">550, c1=-458.649, c2=-389.288 g=414.611\n",
            ">551, c1=-458.032, c2=-391.897 g=417.224\n",
            ">552, c1=-459.506, c2=-394.670 g=418.229\n",
            ">553, c1=-458.737, c2=-393.204 g=419.501\n",
            ">554, c1=-459.823, c2=-395.035 g=419.964\n",
            ">555, c1=-461.226, c2=-396.128 g=421.122\n",
            ">556, c1=-460.546, c2=-391.503 g=420.246\n",
            ">557, c1=-461.372, c2=-394.377 g=421.530\n",
            ">558, c1=-462.956, c2=-396.243 g=422.626\n",
            ">559, c1=-463.734, c2=-395.206 g=421.495\n",
            ">560, c1=-463.275, c2=-398.143 g=422.514\n",
            ">561, c1=-466.148, c2=-401.194 g=424.625\n",
            ">562, c1=-467.721, c2=-407.598 g=426.176\n",
            ">563, c1=-470.915, c2=-413.669 g=428.859\n",
            ">564, c1=-473.665, c2=-417.782 g=430.731\n",
            ">565, c1=-474.989, c2=-422.651 g=435.811\n",
            ">566, c1=-477.633, c2=-427.324 g=437.500\n",
            ">567, c1=-479.367, c2=-428.980 g=440.638\n",
            ">568, c1=-480.454, c2=-431.975 g=441.901\n",
            ">569, c1=-482.517, c2=-433.597 g=443.149\n",
            ">570, c1=-484.415, c2=-436.106 g=445.857\n",
            ">571, c1=-485.887, c2=-439.944 g=447.649\n",
            ">572, c1=-488.062, c2=-441.224 g=449.599\n",
            ">573, c1=-488.811, c2=-442.922 g=451.046\n",
            ">574, c1=-492.041, c2=-446.518 g=453.046\n",
            ">575, c1=-493.727, c2=-449.006 g=455.416\n",
            ">576, c1=-495.158, c2=-450.278 g=456.519\n",
            ">577, c1=-497.829, c2=-452.206 g=459.238\n",
            ">578, c1=-499.894, c2=-455.350 g=460.913\n",
            ">579, c1=-500.577, c2=-456.540 g=462.596\n",
            ">580, c1=-502.454, c2=-455.654 g=463.528\n",
            ">581, c1=-504.382, c2=-457.237 g=464.512\n",
            ">582, c1=-505.143, c2=-459.538 g=466.438\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0582.png and model_0582.h5\n",
            ">583, c1=-506.686, c2=-462.127 g=468.456\n",
            ">584, c1=-510.158, c2=-464.111 g=470.737\n",
            ">585, c1=-511.367, c2=-465.294 g=470.327\n",
            ">586, c1=-512.981, c2=-467.528 g=473.320\n",
            ">587, c1=-513.650, c2=-467.094 g=474.207\n",
            ">588, c1=-515.768, c2=-468.261 g=475.011\n",
            ">589, c1=-517.281, c2=-470.067 g=476.996\n",
            ">590, c1=-518.797, c2=-471.837 g=478.365\n",
            ">591, c1=-520.306, c2=-472.605 g=478.581\n",
            ">592, c1=-521.529, c2=-475.059 g=480.908\n",
            ">593, c1=-523.054, c2=-477.172 g=482.564\n",
            ">594, c1=-524.307, c2=-477.114 g=483.496\n",
            ">595, c1=-526.496, c2=-478.385 g=484.098\n",
            ">596, c1=-527.397, c2=-478.419 g=485.503\n",
            ">597, c1=-529.409, c2=-478.667 g=486.167\n",
            ">598, c1=-529.675, c2=-480.013 g=486.941\n",
            ">599, c1=-531.677, c2=-478.201 g=488.257\n",
            ">600, c1=-532.945, c2=-478.999 g=489.389\n",
            ">601, c1=-533.242, c2=-475.034 g=489.783\n",
            ">602, c1=-533.577, c2=-478.367 g=490.224\n",
            ">603, c1=-536.435, c2=-476.735 g=490.791\n",
            ">604, c1=-536.226, c2=-475.703 g=490.326\n",
            ">605, c1=-535.615, c2=-472.930 g=489.309\n",
            ">606, c1=-536.897, c2=-471.885 g=487.793\n",
            ">607, c1=-537.184, c2=-467.011 g=483.831\n",
            ">608, c1=-538.406, c2=-463.666 g=479.172\n",
            ">609, c1=-538.804, c2=-456.225 g=475.380\n",
            ">610, c1=-537.752, c2=-449.299 g=469.251\n",
            ">611, c1=-538.581, c2=-440.308 g=460.282\n",
            ">612, c1=-536.673, c2=-433.196 g=449.102\n",
            ">613, c1=-536.859, c2=-423.423 g=439.940\n",
            ">614, c1=-537.201, c2=-425.077 g=431.352\n",
            ">615, c1=-536.786, c2=-425.645 g=431.897\n",
            ">616, c1=-539.079, c2=-430.589 g=432.107\n",
            ">617, c1=-539.737, c2=-433.455 g=428.851\n",
            ">618, c1=-540.359, c2=-436.498 g=434.378\n",
            ">619, c1=-542.250, c2=-441.979 g=436.661\n",
            ">620, c1=-543.019, c2=-446.620 g=445.301\n",
            ">621, c1=-543.833, c2=-452.782 g=449.073\n",
            ">622, c1=-545.254, c2=-458.818 g=454.925\n",
            ">623, c1=-546.694, c2=-463.811 g=460.634\n",
            ">624, c1=-547.290, c2=-469.024 g=470.220\n",
            ">625, c1=-548.105, c2=-477.153 g=477.398\n",
            ">626, c1=-549.417, c2=-483.953 g=483.505\n",
            ">627, c1=-550.627, c2=-491.075 g=490.896\n",
            ">628, c1=-551.933, c2=-497.334 g=496.432\n",
            ">629, c1=-553.371, c2=-502.124 g=499.579\n",
            ">630, c1=-555.638, c2=-506.817 g=499.311\n",
            ">631, c1=-558.563, c2=-508.205 g=499.022\n",
            ">632, c1=-561.384, c2=-509.517 g=499.291\n",
            ">633, c1=-562.440, c2=-505.872 g=498.371\n",
            ">634, c1=-563.742, c2=-505.836 g=496.008\n",
            ">635, c1=-564.206, c2=-501.727 g=491.694\n",
            ">636, c1=-563.655, c2=-498.485 g=484.288\n",
            ">637, c1=-564.750, c2=-489.543 g=474.359\n",
            ">638, c1=-561.904, c2=-470.202 g=455.734\n",
            ">639, c1=-556.049, c2=-439.701 g=423.502\n",
            ">640, c1=-548.413, c2=-383.102 g=394.118\n",
            ">641, c1=-537.897, c2=-367.699 g=369.948\n",
            ">642, c1=-534.333, c2=-353.564 g=359.910\n",
            ">643, c1=-530.723, c2=-358.654 g=354.194\n",
            ">644, c1=-529.875, c2=-351.518 g=358.222\n",
            ">645, c1=-533.153, c2=-362.890 g=359.760\n",
            ">646, c1=-529.860, c2=-369.594 g=367.710\n",
            ">647, c1=-532.015, c2=-378.980 g=377.201\n",
            ">648, c1=-531.881, c2=-389.724 g=387.849\n",
            ">649, c1=-534.978, c2=-398.711 g=400.980\n",
            ">650, c1=-537.628, c2=-409.640 g=409.773\n",
            ">651, c1=-537.777, c2=-419.410 g=422.343\n",
            ">652, c1=-537.290, c2=-428.182 g=430.238\n",
            ">653, c1=-541.197, c2=-436.386 g=439.434\n",
            ">654, c1=-542.792, c2=-440.579 g=440.913\n",
            ">655, c1=-537.830, c2=-442.846 g=439.047\n",
            ">656, c1=-541.197, c2=-434.277 g=442.505\n",
            ">657, c1=-541.762, c2=-432.625 g=444.548\n",
            ">658, c1=-535.753, c2=-434.564 g=443.581\n",
            ">659, c1=-539.016, c2=-436.105 g=447.771\n",
            ">660, c1=-536.203, c2=-441.526 g=451.187\n",
            ">661, c1=-536.622, c2=-443.383 g=453.310\n",
            ">662, c1=-529.790, c2=-433.098 g=454.134\n",
            ">663, c1=-528.897, c2=-432.392 g=446.857\n",
            ">664, c1=-525.648, c2=-413.982 g=432.621\n",
            ">665, c1=-522.879, c2=-394.207 g=416.922\n",
            ">666, c1=-511.749, c2=-371.601 g=398.151\n",
            ">667, c1=-494.491, c2=-332.419 g=350.263\n",
            ">668, c1=-480.974, c2=-261.912 g=287.133\n",
            ">669, c1=-455.418, c2=-198.981 g=189.858\n",
            ">670, c1=-441.488, c2=-123.627 g=47.512\n",
            ">671, c1=-416.766, c2=-60.204 g=-72.469\n",
            ">672, c1=-401.840, c2=-8.733 g=-156.664\n",
            ">673, c1=-390.106, c2=-53.023 g=-209.378\n",
            ">674, c1=-380.765, c2=-73.785 g=-247.131\n",
            ">675, c1=-385.596, c2=-85.366 g=-263.224\n",
            ">676, c1=-382.899, c2=-133.433 g=-286.337\n",
            ">677, c1=-386.357, c2=-175.951 g=-328.172\n",
            ">678, c1=-394.782, c2=-198.172 g=-338.062\n",
            ">679, c1=-399.409, c2=-220.390 g=-345.063\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0679.png and model_0679.h5\n",
            ">680, c1=-395.531, c2=-258.932 g=-372.526\n",
            ">681, c1=-408.298, c2=-308.326 g=-393.689\n",
            ">682, c1=-411.513, c2=-299.792 g=-402.167\n",
            ">683, c1=-408.297, c2=-306.193 g=-408.558\n",
            ">684, c1=-422.163, c2=-322.966 g=-419.976\n",
            ">685, c1=-426.295, c2=-332.797 g=-426.892\n",
            ">686, c1=-421.537, c2=-330.560 g=-437.604\n",
            ">687, c1=-431.263, c2=-312.607 g=-426.734\n",
            ">688, c1=-422.360, c2=-336.393 g=-438.310\n",
            ">689, c1=-419.303, c2=-334.796 g=-451.045\n",
            ">690, c1=-433.565, c2=-313.076 g=-445.270\n",
            ">691, c1=-413.181, c2=-279.950 g=-446.847\n",
            ">692, c1=-402.793, c2=-253.312 g=-443.901\n",
            ">693, c1=-387.303, c2=-253.728 g=-440.908\n",
            ">694, c1=-404.012, c2=-219.639 g=-433.776\n",
            ">695, c1=-380.509, c2=-222.667 g=-437.380\n",
            ">696, c1=-353.320, c2=-109.317 g=-429.530\n",
            ">697, c1=-357.729, c2=-105.350 g=-419.408\n",
            ">698, c1=-344.738, c2=10.756 g=-408.178\n",
            ">699, c1=-339.664, c2=40.502 g=-394.408\n",
            ">700, c1=-352.269, c2=87.952 g=-384.061\n",
            ">701, c1=-327.099, c2=23.883 g=-375.984\n",
            ">702, c1=-324.869, c2=149.319 g=-341.695\n",
            ">703, c1=-306.747, c2=115.281 g=-304.213\n",
            ">704, c1=-314.861, c2=116.798 g=-285.680\n",
            ">705, c1=-306.450, c2=60.742 g=-293.749\n",
            ">706, c1=-311.620, c2=41.521 g=-297.291\n",
            ">707, c1=-303.549, c2=58.873 g=-273.079\n",
            ">708, c1=-299.471, c2=84.750 g=-255.641\n",
            ">709, c1=-289.591, c2=86.812 g=-237.097\n",
            ">710, c1=-287.307, c2=100.079 g=-205.988\n",
            ">711, c1=-271.154, c2=88.446 g=-159.876\n",
            ">712, c1=-258.321, c2=82.959 g=-114.968\n",
            ">713, c1=-253.556, c2=53.102 g=-91.188\n",
            ">714, c1=-247.089, c2=33.977 g=-74.178\n",
            ">715, c1=-232.968, c2=25.125 g=-48.431\n",
            ">716, c1=-234.957, c2=10.058 g=-26.006\n",
            ">717, c1=-227.195, c2=12.303 g=-4.886\n",
            ">718, c1=-217.888, c2=-4.162 g=28.016\n",
            ">719, c1=-219.891, c2=-4.220 g=44.820\n",
            ">720, c1=-223.051, c2=-9.566 g=43.318\n",
            ">721, c1=-217.013, c2=-3.581 g=56.334\n",
            ">722, c1=-205.761, c2=-17.975 g=52.470\n",
            ">723, c1=-205.814, c2=-31.638 g=82.907\n",
            ">724, c1=-200.002, c2=-27.598 g=94.765\n",
            ">725, c1=-205.236, c2=-65.722 g=119.674\n",
            ">726, c1=-189.023, c2=-60.023 g=139.913\n",
            ">727, c1=-206.585, c2=-69.398 g=157.640\n",
            ">728, c1=-198.962, c2=-98.100 g=184.571\n",
            ">729, c1=-213.966, c2=-118.279 g=213.226\n",
            ">730, c1=-210.261, c2=-112.638 g=225.281\n",
            ">731, c1=-191.904, c2=-125.407 g=246.037\n",
            ">732, c1=-215.615, c2=-122.586 g=253.814\n",
            ">733, c1=-201.974, c2=-140.645 g=274.553\n",
            ">734, c1=-209.508, c2=-141.364 g=286.848\n",
            ">735, c1=-209.615, c2=-151.628 g=291.720\n",
            ">736, c1=-230.028, c2=-188.825 g=304.429\n",
            ">737, c1=-221.077, c2=-224.184 g=325.169\n",
            ">738, c1=-259.848, c2=-261.758 g=346.915\n",
            ">739, c1=-254.645, c2=-272.976 g=368.883\n",
            ">740, c1=-265.271, c2=-286.086 g=390.303\n",
            ">741, c1=-277.364, c2=-287.364 g=408.843\n",
            ">742, c1=-266.603, c2=-270.492 g=421.072\n",
            ">743, c1=-289.693, c2=-244.558 g=416.870\n",
            ">744, c1=-263.188, c2=-266.886 g=423.570\n",
            ">745, c1=-301.656, c2=-262.137 g=425.714\n",
            ">746, c1=-291.517, c2=-292.077 g=432.742\n",
            ">747, c1=-302.395, c2=-340.249 g=443.854\n",
            ">748, c1=-320.465, c2=-372.200 g=456.063\n",
            ">749, c1=-342.290, c2=-363.640 g=465.849\n",
            ">750, c1=-316.430, c2=-356.951 g=480.168\n",
            ">751, c1=-326.058, c2=-278.550 g=478.026\n",
            ">752, c1=-331.712, c2=-267.902 g=478.298\n",
            ">753, c1=-301.389, c2=-243.269 g=469.751\n",
            ">754, c1=-316.862, c2=-257.473 g=465.056\n",
            ">755, c1=-300.919, c2=-286.982 g=453.224\n",
            ">756, c1=-360.827, c2=-316.683 g=440.326\n",
            ">757, c1=-361.920, c2=-325.979 g=430.782\n",
            ">758, c1=-390.241, c2=-354.763 g=432.421\n",
            ">759, c1=-380.132, c2=-403.496 g=454.736\n",
            ">760, c1=-415.351, c2=-446.495 g=469.154\n",
            ">761, c1=-433.236, c2=-462.846 g=483.654\n",
            ">762, c1=-442.479, c2=-476.268 g=504.570\n",
            ">763, c1=-454.720, c2=-479.954 g=521.857\n",
            ">764, c1=-450.820, c2=-470.881 g=527.831\n",
            ">765, c1=-448.188, c2=-456.239 g=532.200\n",
            ">766, c1=-429.993, c2=-446.244 g=533.300\n",
            ">767, c1=-441.344, c2=-417.521 g=530.104\n",
            ">768, c1=-434.634, c2=-450.100 g=529.311\n",
            ">769, c1=-427.257, c2=-399.884 g=519.582\n",
            ">770, c1=-431.565, c2=-417.969 g=510.340\n",
            ">771, c1=-433.763, c2=-452.197 g=522.255\n",
            ">772, c1=-455.082, c2=-489.884 g=533.334\n",
            ">773, c1=-456.917, c2=-486.949 g=527.989\n",
            ">774, c1=-469.517, c2=-496.160 g=529.965\n",
            ">775, c1=-473.695, c2=-475.024 g=533.473\n",
            ">776, c1=-472.288, c2=-482.290 g=528.054\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0776.png and model_0776.h5\n",
            ">777, c1=-486.191, c2=-479.056 g=533.220\n",
            ">778, c1=-475.146, c2=-460.446 g=513.449\n",
            ">779, c1=-457.215, c2=-409.360 g=495.845\n",
            ">780, c1=-429.150, c2=-352.652 g=486.755\n",
            ">781, c1=-434.656, c2=-336.588 g=476.275\n",
            ">782, c1=-389.688, c2=-174.296 g=409.501\n",
            ">783, c1=-388.840, c2=93.579 g=213.929\n",
            ">784, c1=-365.555, c2=158.833 g=-159.291\n",
            ">785, c1=-410.179, c2=250.914 g=-250.779\n",
            ">786, c1=-423.856, c2=281.217 g=-342.445\n",
            ">787, c1=-449.714, c2=306.836 g=-367.831\n",
            ">788, c1=-470.525, c2=318.334 g=-396.802\n",
            ">789, c1=-468.622, c2=310.562 g=-387.970\n",
            ">790, c1=-465.539, c2=288.913 g=-391.161\n",
            ">791, c1=-458.077, c2=269.293 g=-394.422\n",
            ">792, c1=-456.519, c2=246.232 g=-374.787\n",
            ">793, c1=-438.278, c2=213.412 g=-390.241\n",
            ">794, c1=-434.454, c2=206.476 g=-375.236\n",
            ">795, c1=-425.622, c2=182.780 g=-378.729\n",
            ">796, c1=-416.493, c2=170.205 g=-369.457\n",
            ">797, c1=-417.814, c2=160.443 g=-371.610\n",
            ">798, c1=-397.446, c2=186.123 g=-370.446\n",
            ">799, c1=-389.752, c2=160.511 g=-356.585\n",
            ">800, c1=-380.406, c2=221.128 g=-331.261\n",
            ">801, c1=-375.872, c2=100.796 g=-329.991\n",
            ">802, c1=-377.520, c2=63.305 g=-336.888\n",
            ">803, c1=-370.405, c2=97.580 g=-323.660\n",
            ">804, c1=-332.832, c2=155.661 g=-297.294\n",
            ">805, c1=-350.544, c2=41.947 g=-323.514\n",
            ">806, c1=-357.917, c2=116.432 g=-300.224\n",
            ">807, c1=-325.238, c2=92.508 g=-315.470\n",
            ">808, c1=-324.190, c2=204.597 g=-294.133\n",
            ">809, c1=-320.619, c2=150.578 g=-306.401\n",
            ">810, c1=-308.293, c2=169.119 g=-288.165\n",
            ">811, c1=-302.318, c2=107.516 g=-297.022\n",
            ">812, c1=-288.600, c2=110.297 g=-286.401\n",
            ">813, c1=-287.383, c2=180.442 g=-280.043\n",
            ">814, c1=-296.080, c2=125.040 g=-267.041\n",
            ">815, c1=-269.279, c2=192.811 g=-281.855\n",
            ">816, c1=-291.167, c2=167.418 g=-264.749\n",
            ">817, c1=-265.891, c2=173.550 g=-278.315\n",
            ">818, c1=-290.843, c2=248.098 g=-259.459\n",
            ">819, c1=-255.367, c2=216.308 g=-255.122\n",
            ">820, c1=-272.221, c2=200.061 g=-241.971\n",
            ">821, c1=-251.335, c2=230.973 g=-252.500\n",
            ">822, c1=-253.006, c2=233.948 g=-245.357\n",
            ">823, c1=-251.649, c2=210.231 g=-249.246\n",
            ">824, c1=-241.658, c2=201.194 g=-234.407\n",
            ">825, c1=-251.191, c2=210.216 g=-226.680\n",
            ">826, c1=-224.281, c2=236.750 g=-211.043\n",
            ">827, c1=-239.592, c2=164.283 g=-217.083\n",
            ">828, c1=-217.816, c2=200.133 g=-210.597\n",
            ">829, c1=-235.791, c2=207.504 g=-210.758\n",
            ">830, c1=-218.736, c2=220.062 g=-199.160\n",
            ">831, c1=-243.625, c2=202.951 g=-203.687\n",
            ">832, c1=-204.788, c2=210.309 g=-188.262\n",
            ">833, c1=-224.853, c2=188.843 g=-197.114\n",
            ">834, c1=-226.862, c2=220.239 g=-188.228\n",
            ">835, c1=-219.308, c2=200.107 g=-185.238\n",
            ">836, c1=-224.767, c2=212.055 g=-177.544\n",
            ">837, c1=-217.319, c2=197.782 g=-177.216\n",
            ">838, c1=-216.340, c2=188.487 g=-187.546\n",
            ">839, c1=-217.955, c2=204.967 g=-181.228\n",
            ">840, c1=-226.460, c2=214.285 g=-171.989\n",
            ">841, c1=-218.025, c2=205.209 g=-180.323\n",
            ">842, c1=-213.714, c2=206.146 g=-170.099\n",
            ">843, c1=-216.687, c2=198.907 g=-165.682\n",
            ">844, c1=-204.620, c2=201.520 g=-156.913\n",
            ">845, c1=-211.582, c2=177.170 g=-167.691\n",
            ">846, c1=-216.631, c2=187.425 g=-170.312\n",
            ">847, c1=-211.952, c2=199.796 g=-171.946\n",
            ">848, c1=-204.659, c2=202.310 g=-160.434\n",
            ">849, c1=-214.885, c2=186.834 g=-164.988\n",
            ">850, c1=-221.609, c2=191.254 g=-175.530\n",
            ">851, c1=-201.392, c2=190.876 g=-176.649\n",
            ">852, c1=-222.951, c2=207.875 g=-170.670\n",
            ">853, c1=-221.701, c2=196.877 g=-175.938\n",
            ">854, c1=-214.978, c2=196.272 g=-158.506\n",
            ">855, c1=-212.938, c2=187.675 g=-167.415\n",
            ">856, c1=-214.149, c2=184.482 g=-186.392\n",
            ">857, c1=-217.099, c2=203.066 g=-172.663\n",
            ">858, c1=-213.861, c2=181.167 g=-186.210\n",
            ">859, c1=-215.647, c2=199.400 g=-184.071\n",
            ">860, c1=-217.053, c2=208.589 g=-185.319\n",
            ">861, c1=-217.051, c2=186.817 g=-184.184\n",
            ">862, c1=-222.864, c2=204.410 g=-189.483\n",
            ">863, c1=-214.196, c2=189.183 g=-185.779\n",
            ">864, c1=-219.760, c2=207.609 g=-174.594\n",
            ">865, c1=-223.858, c2=192.871 g=-181.089\n",
            ">866, c1=-219.588, c2=193.885 g=-184.621\n",
            ">867, c1=-211.173, c2=187.031 g=-180.924\n",
            ">868, c1=-216.230, c2=203.504 g=-157.812\n",
            ">869, c1=-224.479, c2=206.585 g=-175.186\n",
            ">870, c1=-218.633, c2=208.551 g=-179.395\n",
            ">871, c1=-233.019, c2=200.501 g=-191.929\n",
            ">872, c1=-218.074, c2=185.575 g=-186.118\n",
            ">873, c1=-219.839, c2=193.571 g=-183.656\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0873.png and model_0873.h5\n",
            ">874, c1=-213.187, c2=204.310 g=-177.883\n",
            ">875, c1=-223.192, c2=206.952 g=-182.600\n",
            ">876, c1=-217.023, c2=191.018 g=-180.642\n",
            ">877, c1=-224.113, c2=164.488 g=-188.685\n",
            ">878, c1=-223.752, c2=195.558 g=-180.693\n",
            ">879, c1=-226.013, c2=169.159 g=-177.891\n",
            ">880, c1=-220.655, c2=194.138 g=-190.679\n",
            ">881, c1=-220.388, c2=190.929 g=-187.460\n",
            ">882, c1=-204.426, c2=189.287 g=-190.697\n",
            ">883, c1=-216.311, c2=171.210 g=-193.036\n",
            ">884, c1=-201.992, c2=188.524 g=-197.934\n",
            ">885, c1=-218.730, c2=193.518 g=-191.069\n",
            ">886, c1=-206.077, c2=181.933 g=-191.912\n",
            ">887, c1=-210.755, c2=171.994 g=-195.426\n",
            ">888, c1=-217.838, c2=176.415 g=-193.485\n",
            ">889, c1=-208.317, c2=188.442 g=-192.846\n",
            ">890, c1=-203.072, c2=192.199 g=-188.649\n",
            ">891, c1=-198.740, c2=167.508 g=-185.850\n",
            ">892, c1=-210.369, c2=149.738 g=-191.802\n",
            ">893, c1=-202.884, c2=198.266 g=-172.196\n",
            ">894, c1=-197.516, c2=201.133 g=-167.603\n",
            ">895, c1=-212.248, c2=183.209 g=-185.181\n",
            ">896, c1=-204.321, c2=175.192 g=-187.933\n",
            ">897, c1=-206.944, c2=172.642 g=-181.667\n",
            ">898, c1=-207.219, c2=197.450 g=-177.088\n",
            ">899, c1=-224.094, c2=174.373 g=-188.384\n",
            ">900, c1=-184.112, c2=178.538 g=-182.469\n",
            ">901, c1=-193.568, c2=166.988 g=-178.048\n",
            ">902, c1=-201.473, c2=161.760 g=-184.506\n",
            ">903, c1=-194.828, c2=149.656 g=-177.837\n",
            ">904, c1=-189.278, c2=178.507 g=-183.700\n",
            ">905, c1=-185.672, c2=168.638 g=-179.597\n",
            ">906, c1=-189.152, c2=171.491 g=-182.237\n",
            ">907, c1=-202.835, c2=158.961 g=-183.803\n",
            ">908, c1=-201.931, c2=190.958 g=-182.270\n",
            ">909, c1=-196.029, c2=183.206 g=-186.194\n",
            ">910, c1=-195.138, c2=193.039 g=-177.238\n",
            ">911, c1=-209.474, c2=183.248 g=-180.858\n",
            ">912, c1=-192.006, c2=186.289 g=-183.412\n",
            ">913, c1=-201.934, c2=178.169 g=-181.076\n",
            ">914, c1=-195.268, c2=182.812 g=-178.691\n",
            ">915, c1=-199.720, c2=184.081 g=-177.878\n",
            ">916, c1=-203.553, c2=184.182 g=-179.458\n",
            ">917, c1=-193.037, c2=184.223 g=-174.614\n",
            ">918, c1=-195.763, c2=183.076 g=-175.438\n",
            ">919, c1=-186.049, c2=191.281 g=-164.048\n",
            ">920, c1=-190.223, c2=188.344 g=-167.016\n",
            ">921, c1=-195.397, c2=181.184 g=-170.660\n",
            ">922, c1=-192.517, c2=178.630 g=-172.500\n",
            ">923, c1=-195.200, c2=183.194 g=-175.783\n",
            ">924, c1=-196.306, c2=184.193 g=-171.704\n",
            ">925, c1=-200.528, c2=192.064 g=-169.060\n",
            ">926, c1=-198.048, c2=187.939 g=-166.337\n",
            ">927, c1=-191.918, c2=186.587 g=-165.878\n",
            ">928, c1=-193.402, c2=185.551 g=-162.527\n",
            ">929, c1=-194.454, c2=184.594 g=-156.206\n",
            ">930, c1=-190.830, c2=182.778 g=-161.090\n",
            ">931, c1=-197.928, c2=183.259 g=-160.409\n",
            ">932, c1=-198.116, c2=182.783 g=-159.968\n",
            ">933, c1=-199.979, c2=182.331 g=-161.285\n",
            ">934, c1=-200.500, c2=184.640 g=-161.305\n",
            ">935, c1=-198.297, c2=183.967 g=-161.365\n",
            ">936, c1=-202.449, c2=180.443 g=-157.099\n",
            ">937, c1=-200.870, c2=182.464 g=-161.338\n",
            ">938, c1=-198.812, c2=183.244 g=-155.268\n",
            ">939, c1=-200.533, c2=180.962 g=-163.926\n",
            ">940, c1=-199.241, c2=185.103 g=-162.789\n",
            ">941, c1=-198.628, c2=186.554 g=-165.469\n",
            ">942, c1=-199.990, c2=185.794 g=-163.203\n",
            ">943, c1=-200.914, c2=187.457 g=-172.523\n",
            ">944, c1=-198.779, c2=191.424 g=-166.342\n",
            ">945, c1=-201.640, c2=191.459 g=-167.916\n",
            ">946, c1=-205.731, c2=191.107 g=-168.106\n",
            ">947, c1=-203.546, c2=189.161 g=-171.576\n",
            ">948, c1=-206.341, c2=191.027 g=-170.749\n",
            ">949, c1=-205.067, c2=189.173 g=-166.768\n",
            ">950, c1=-207.513, c2=184.651 g=-168.774\n",
            ">951, c1=-207.653, c2=188.559 g=-173.420\n",
            ">952, c1=-213.615, c2=185.135 g=-175.256\n",
            ">953, c1=-214.205, c2=179.078 g=-178.047\n",
            ">954, c1=-212.216, c2=189.639 g=-176.436\n",
            ">955, c1=-217.900, c2=185.130 g=-176.967\n",
            ">956, c1=-211.773, c2=194.957 g=-178.371\n",
            ">957, c1=-217.762, c2=188.738 g=-187.265\n",
            ">958, c1=-213.727, c2=184.289 g=-188.055\n",
            ">959, c1=-214.003, c2=181.472 g=-189.674\n",
            ">960, c1=-213.192, c2=182.686 g=-195.568\n",
            ">961, c1=-210.756, c2=179.391 g=-195.796\n",
            ">962, c1=-210.455, c2=187.793 g=-200.824\n",
            ">963, c1=-212.570, c2=187.071 g=-199.226\n",
            ">964, c1=-217.530, c2=184.568 g=-201.794\n",
            ">965, c1=-214.782, c2=182.429 g=-197.914\n",
            ">966, c1=-219.398, c2=180.964 g=-198.558\n",
            ">967, c1=-213.477, c2=194.128 g=-195.908\n",
            ">968, c1=-213.387, c2=187.222 g=-198.066\n",
            ">969, c1=-217.773, c2=187.080 g=-198.642\n",
            ">970, c1=-213.509, c2=188.430 g=-203.874\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            ">Saved: generated_plot_0970.png and model_0970.h5\n"
          ]
        }
      ],
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras import backend\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.constraints import Constraint\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# clip model weights to a given hypercube\n",
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        " \n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
        " \n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}\n",
        " \n",
        "# calculate wasserstein loss\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "\treturn backend.mean(y_true * y_pred)\n",
        " \n",
        "# define the standalone critic model\n",
        "def define_critic(in_shape=(28,28,1)):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# weight constraint\n",
        "\tconst = ClipConstraint(0.01)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# downsample to 14x14\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 7x7\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# scoring, linear activation\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1))\n",
        "\t# compile model\n",
        "\topt = RMSprop(lr=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output 28x28x1\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
        "\treturn model\n",
        " \n",
        "# define the combined generator and critic model, for updating the generator\n",
        "def define_gan(generator, critic):\n",
        "\t# make weights in the critic not trainable\n",
        "\tfor layer in critic.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the critic\n",
        "\tmodel.add(critic)\n",
        "\t# compile model\n",
        "\topt = RMSprop(lr=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        " \n",
        "# load images\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, trainy), (_, _) = load_data()\n",
        "\t# select all of the examples for a given class\n",
        "\tselected_ix = trainy == 7\n",
        "\tX = trainX[selected_ix]\n",
        "\t# expand to 3d, e.g. add channels\n",
        "\tX = expand_dims(X, axis=-1)\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X\n",
        " \n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels, -1 for 'real'\n",
        "\ty = -ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        " \n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels with 1.0 for 'fake'\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        " \n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(10 * 10):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        " \n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "\t# plot history\n",
        "\tpyplot.plot(d1_hist, label='crit_real')\n",
        "\tpyplot.plot(d2_hist, label='crit_fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\tpyplot.savefig('plot_line_plot_loss.png')\n",
        "\tpyplot.close()\n",
        " \n",
        "# train the generator and critic\n",
        "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the size of half a batch of samples\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# lists for keeping track of loss\n",
        "\tc1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# update the critic more than the generator\n",
        "\t\tc1_tmp, c2_tmp = list(), list()\n",
        "\t\tfor _ in range(n_critic):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# update critic model weights\n",
        "\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)\n",
        "\t\t\tc1_tmp.append(c_loss1)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update critic model weights\n",
        "\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\tc2_tmp.append(c_loss2)\n",
        "\t\t# store critic loss\n",
        "\t\tc1_hist.append(mean(c1_tmp))\n",
        "\t\tc2_hist.append(mean(c2_tmp))\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = -ones((n_batch, 1))\n",
        "\t\t# update the generator via the critic's error\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\tg_hist.append(g_loss)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
        "\t\t# evaluate the model performance every 'epoch'\n",
        "\t\tif (i+1) % bat_per_epo == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
        "\t# line plots of loss\n",
        "\tplot_history(c1_hist, c2_hist, g_hist)\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 50\n",
        "# create the critic\n",
        "critic = define_critic()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, critic)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)\n",
        "# train model\n",
        "train(generator, critic, gan_model, dataset, latent_dim)"
      ]
    }
  ]
}